{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = 'AKIAWOHFNKOOBLZJIZEU'\n",
    "secret_key = '---INSERT SECRET KEY HERE---'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and predefining functions\n",
    "\n",
    "us = {'Alabama': 'AL',\n",
    " 'Alaska': 'AK',\n",
    " 'American Samoa': 'AS',\n",
    " 'Arizona': 'AZ',\n",
    " 'Arkansas': 'AR',\n",
    " 'California': 'CA',\n",
    " 'Colorado': 'CO',\n",
    " 'Connecticut': 'CT',\n",
    " 'Dakota': 'DK',\n",
    " 'Delaware': 'DE',\n",
    " 'District of Columbia': 'DC',\n",
    " 'Florida': 'FL',\n",
    " 'Georgia': 'GA',\n",
    " 'Guam': 'GU',\n",
    " 'Hawaii': 'HI',\n",
    " 'Idaho': 'ID',\n",
    " 'Illinois': 'IL',\n",
    " 'Indiana': 'IN',\n",
    " 'Iowa': 'IA',\n",
    " 'Kansas': 'KS',\n",
    " 'Kentucky': 'KY',\n",
    " 'Louisiana': 'LA',\n",
    " 'Maine': 'ME',\n",
    " 'Maryland': 'MD',\n",
    " 'Massachusetts': 'MA',\n",
    " 'Michigan': 'MI',\n",
    " 'Minnesota': 'MN',\n",
    " 'Mississippi': 'MS',\n",
    " 'Missouri': 'MO',\n",
    " 'Montana': 'MT',\n",
    " 'Nebraska': 'NE',\n",
    " 'Nevada': 'NV',\n",
    " 'New Hampshire': 'NH',\n",
    " 'New Jersey': 'NJ',\n",
    " 'New Mexico': 'NM',\n",
    " 'New York': 'NY',\n",
    " 'North Carolina': 'NC',\n",
    " 'North Dakota': 'ND',\n",
    " 'Northern Mariana Islands': 'MP',\n",
    " 'Ohio': 'OH',\n",
    " 'Oklahoma': 'OK',\n",
    " 'Oregon': 'OR',\n",
    " 'Orleans': 'OL',\n",
    " 'Pennsylvania': 'PA',\n",
    " 'Philippine Islands': 'PI',\n",
    " 'Puerto Rico': 'PR',\n",
    " 'Rhode Island': 'RI',\n",
    " 'South Carolina': 'SC',\n",
    " 'South Dakota': 'SD',\n",
    " 'Tennessee': 'TN',\n",
    " 'Texas': 'TX',\n",
    " 'Utah': 'UT',\n",
    " 'Vermont': 'VT',\n",
    " 'Virgin Islands': 'VI',\n",
    " 'Virginia': 'VA',\n",
    " 'Washington': 'WA',\n",
    " 'West Virginia': 'WV',\n",
    " 'Wisconsin': 'WI',\n",
    " 'Wyoming': 'WY'}\n",
    "\n",
    "test_mode = False\n",
    "\n",
    "s3 = {'i_rate': 's3a://msds-durian-candy/insurance/Rate.csv.gz',\n",
    "      'i_plan': 's3a://msds-durian-candy/insurance/PlanAttributes.csv.gz',\n",
    "      'census': 's3a://msds-durian-candy/census/acs2015_county_data.csv.gz'}\n",
    "\n",
    "test = {'i_rate': '../data/test/insurance_Rate.csv',\n",
    "        'i_plan': '../data/s3/insurance/PlanAttributes.csv',\n",
    "        'census': '../data/s3/census/acs2015_county_data.csv'}\n",
    "\n",
    "source = test if test_mode else s3\n",
    "\n",
    "def csv_split(x):\n",
    "    return next(csv.reader([x], delimiter=',', quotechar='\"'))\n",
    "\n",
    "# Load insurance Data\n",
    "i_rate = sc.textFile(source['i_rate']).map(csv_split)\n",
    "i_plan = sc.textFile(source['i_plan']).map(csv_split)\n",
    "i_rate_h = i_rate.first()\n",
    "i_plan_h = i_plan.first()\n",
    "i_rate_rows = i_rate.filter(lambda x: x != i_rate_h)\n",
    "i_plan_rows = i_plan.filter(lambda x: x != i_plan_h)\n",
    "\n",
    "i_rate_kv = (i_rate_rows\n",
    "             .filter(lambda x: 1 < float(x[i_rate_h.index('IndividualRate')]) < 9999)\n",
    "             .map(lambda x: (x[i_rate_h.index('PlanId')], (x[i_rate_h.index('StateCode')], float(x[i_rate_h.index('IndividualRate')])))))\n",
    "i_plan_kv = i_plan_rows.map(lambda x: (x[i_plan_h.index('StandardComponentId')], x[i_plan_h.index('PlanType')]))\n",
    "\n",
    "i_kv = i_rate_kv.leftOuterJoin(i_plan_kv).map(lambda x: ((x[1][0][0], x[1][1]), (x[1][0][1], 1)))\n",
    "i_r = i_kv.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).mapValues(lambda x: x[0] / x[1]).map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "\n",
    "# Load Census Data\n",
    "census = sc.textFile(source['census']).map(csv_split)\n",
    "census_h = census.first()\n",
    "census_rows = census.filter(lambda x: x != census_h)\n",
    "\n",
    "census_kv = (census_rows\n",
    "             .map(lambda x: (us[x[census_h.index('State')]], x[3:]))\n",
    "             .mapValues(lambda row: [float(val) if val else 0 for val in row])\n",
    "             .mapValues(lambda row: [1] + row))\n",
    "census_r = (census_kv\n",
    "            .reduceByKey(lambda list1, list2: [sum(x) for x in zip(list1, list2)])\n",
    "            .mapValues(lambda row: [x / row[0] for x in row]))\n",
    "\n",
    "df_r = i_r.leftOuterJoin(census_r).map(lambda x: (x[0], x[1][0][0], x[1][0][1], *x[1][1][1:])).sortBy(lambda x: x[0])\n",
    "\n",
    "df_ins_h = ('State', 'PlanType', 'IndividualRate', *census_h[3:])\n",
    "df_insurance_census = df_r.collect()\n",
    "\n",
    "df_insurance_census.insert(0,df_ins_h)\n",
    "\n",
    "### Rent data\n",
    "# Unpivot Rent Data\n",
    "\n",
    "rdd_rent = sc.textFile('s3a://msds-durian-candy/rent/Metro_Zri_AllHomesPlusMultifamily.csv.gz')\n",
    "\n",
    "header_raw = rdd_rent.first()\n",
    "header_temp = [item for item in csv.reader([header_raw])][0]\n",
    "\n",
    "new_header = []\n",
    "new_header.append(header_temp[0]) # RegionID\n",
    "new_header.extend(['RegionName','StateCode']) # RegionName to 'StateName' and 'StateCode'\n",
    "new_header.append(header_temp[2])\n",
    "new_header.extend(['Year','Month']) # From index 3 onwards is date related, we want long format of those columns\n",
    "new_header.append('ZillowRentIndex')\n",
    "\n",
    "# The first row is also useless for us since it's for the entire US not individual state\n",
    "US_row = rdd_rent.filter(lambda line: line != header_raw).first()\n",
    "\n",
    "def unpivot_widerow_to_longrows(row,header_original):\n",
    "    new_row_base = []\n",
    "    new_row_base.append(row[0])\n",
    "    new_row_base.extend([state_data.strip() for state_data in row[1].split(',')])\n",
    "    new_row_base.append(row[2])\n",
    "    \n",
    "    year_month_list = [year_month.split('-') for year_month in header_original[3:]]\n",
    "    prices = row[3:]\n",
    "    \n",
    "    unpivoted_rows = []\n",
    "    for i in range(len(year_month_list)):\n",
    "        year_month_list[i].append(prices[i])\n",
    "        new_row = new_row_base + year_month_list[i]\n",
    "        unpivoted_rows.append(new_row)\n",
    "    \n",
    "    return unpivoted_rows\n",
    "\n",
    "unpivoted_rent = (rdd_rent.filter(lambda line: line != header_raw)\n",
    "         .filter(lambda line: line != US_row)\n",
    "         .map(lambda row_raw_csv: [item for item in csv.reader([row_raw_csv])][0])\n",
    "         .flatMap(lambda row: unpivot_widerow_to_longrows(row,header_temp) )\n",
    ")\n",
    "\n",
    "# Aggregate (average) Zillow Rent Index by State and Year\n",
    "\n",
    "mean_zri = (unpivoted_rent.filter(lambda x: x[6] != '') # Drop null in ZRI\n",
    "                .map(lambda x: [int(x[i].strip()) if i==4 else x[i] for i in range(len(x))]) # Year to Int\n",
    "                .map(lambda x: [float(x[i].strip()) if i==6 else x[i] for i in range(len(x))]) # ZRI to Float\n",
    "                # We are only interested in year 2014,2015,2016\n",
    "                .filter(lambda x: x[4] >= 2014 and x[4] <= 2016 ) \n",
    "                # (key=(State,Year) , value=(ZRI,1)), the 1 is for averaging use \n",
    "                .map(lambda x: ((x[2],x[4]),(x[6],1)) ) \n",
    "                .reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "                .mapValues(lambda x: x[0]/x[1])\n",
    "                .map(lambda x: (x[0][0],x[0][1],x[1]))\n",
    ")\n",
    "\n",
    "mean_zri_list = mean_zri.collect()\n",
    "\n",
    "# Get Yearly Insurance Data\n",
    "\n",
    "i_rate_kv = (i_rate_rows\n",
    "             .filter(lambda x: 1 < float(x[i_rate_h.index('IndividualRate')]) < 9999)\n",
    "             .map(lambda x: (x[i_rate_h.index('PlanId')], \n",
    "                            ((x[i_rate_h.index('BusinessYear')],x[i_rate_h.index('StateCode')]),\n",
    "                            float(x[i_rate_h.index('IndividualRate')])))))\n",
    "i_plan_kv = i_plan_rows.map(lambda x: (x[i_plan_h.index('StandardComponentId')], x[i_plan_h.index('PlanType')]))\n",
    "\n",
    "i_kv = i_rate_kv.leftOuterJoin(i_plan_kv).map(lambda x: ((x[1][0][0], x[1][1]), (x[1][0][1], 1)))\n",
    "i_r = i_kv.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).mapValues(lambda x: x[0] / x[1]).map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "\n",
    "df_r = i_r.map(lambda x: (x[0][1],int(x[0][0]),x[1][0],x[1][1]) ) # StateCode,Year,PlanType,AvgIndvRate\n",
    "\n",
    "joined_rdd = mean_zri.map(lambda x: ((x[0],x[1]),x[2])).join(df_r.map(lambda x: ((x[0],x[1]),(x[2],x[3]))))\n",
    "\n",
    "all_df = joined_rdd.map(lambda x: (x[0][0],x[0][1],x[1][0],x[1][1][0],x[1][1][1]))\n",
    "\n",
    "df_rent = (all_df.map(lambda x: ((x[1],x[3]),(x[2],x[4],1)))\n",
    "       .reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1],x[2]+y[2]) )\n",
    "       .map(lambda x: (x[0][0],x[0][1],x[1][0]/x[1][2],x[1][1]/x[1][2]))\n",
    ").collect()\n",
    "\n",
    "df_h = ('Year', 'PlanType', 'MeanZRI',  'IndividualRate')\n",
    "\n",
    "df_rent.insert(0,tuple(df_h))\n",
    "\n",
    "insurance_data = sc.parallelize(df_insurance_census)\n",
    "rent_data =  sc.parallelize(df_rent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works the first time, unless the s3 file is deleted. PySpark RDD cannot overwrite files.\n",
    "#insurance_data.saveAsTextFile('s3a://msds-durian-candy/vizdata/insurance_data')\n",
    "#rent_data.saveAsTextFile('s3a://msds-durian-candy/vizdata/rent_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
